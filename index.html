<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Distributed Systems Reading Group</title>
  <meta name="description" content="DSRG is a Distributed Systems Reading Group at MIT. We meet once a week on the 9th floor of Stata to discuss distributed systems research papers, and cover papers from conferences like SOSP, OSDI, PODC, VLDB, and SIGMOD. We try to have a healthy mix of current systems papers and older seminal papers.
">

  <base href="/" />
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://dsrg.pdos.csail.mit.edu/">
  <link rel="alternate" type="application/rss+xml" title="Distributed Systems Reading Group" href="http://dsrg.pdos.csail.mit.edu/feed.xml" />
  <link href='/stylesheets/all-b5d41f4fa671ec94597e984da68527b0.css' media='all' rel='stylesheet' type='text/css'>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>

  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Distributed Systems Reading Group</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/papers/">Papers</a>
          
        
          
          <a class="page-link" href="/schedule/">Schedule</a>
          
        
      </div>
    </nav>

  </div>

</header>

    <div class="page-content">
      <div class="wrapper">
        <div class="home">

  <ul class="post-list">
    
      <li>
        <span class="post-meta">Jan 10, 2014</span>
        <h2>
          <a class="post-link" href="/2014/01/10/epaxos/">EPaxos</a>
        </h2>
	<p>
	  <p><a href="https://github.com/efficient/epaxos">EPaxos</a> is a leaderless Paxos
variant which tries to reduce latencies for a geo-distributed replica
group by enabling the client to use the replica with the lowest
round-trip latency as the operation leader, and optimistically skipping
a round of replica communication by inter-operation conflict detection</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Dec 16, 2013</span>
        <h2>
          <a class="post-link" href="/2013/12/16/sinfonia/">Sinfonia</a>
        </h2>
	<p>
	  <p><a href="http://www.cs.princeton.edu/courses/archive/fall08/cos597B/papers/sinfonia.pdf">Sinfonia</a>
is a service that allows hosts to share application data in a
fault-tolerant, scalable, and consistent manner using a novel
mini-transaction primitive. We read this paper because it provides an
interesting alternative to message passing for building distributed
systems.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Sep 30, 2013</span>
        <h2>
          <a class="post-link" href="/2013/09/30/spark-streaming/">Discretized Streams</a>
        </h2>
	<p>
	  <p><a href="http://sigops.org/sosp/sosp13/papers/p423-zaharia.pdf">Discretized Streams: Fault Tolerant Computing at
Scale</a> describes
additions to the
<a href="http://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">Spark</a>
system to handle streaming data. Compared to other streaming systems,
Spark Streaming offers a more robust fault recovery and straggler
handling strategies using the Resilient Distributed Dataset (RDD) memory
abstraction. In addition to allowing parallel recovery, Spark Streaming
is one of the first systems which can incorporate batch and interactive
query models all within the same system.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Sep 30, 2013</span>
        <h2>
          <a class="post-link" href="/2013/09/30/spanstore/">SPANStore</a>
        </h2>
	<p>
	  <p>Several cloud providers provide storage in many data centers globally,
and customers can use simple PUTs and GETs to store and retrieve data
without dealing with the complexities of the storage infrastructure.
However, in reality, every storage system leaves replication across data
centers to the application, and although replication across all data
centers provides low latency, it is expensive.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Aug 8, 2013</span>
        <h2>
          <a class="post-link" href="/2013/08/08/chain-replication/">Chain Replication</a>
        </h2>
	<p>
	  <p><a href="http://db2.usenix.org/events/osdi04/tech/full_papers/renesse/renesse.pdf">Chain
Replication</a>
is a paper from ‘04 by Renesse and Schneider. The system is interesting,
because it is a primary-backup system with an unconventional
architecture that aimed to achieve high throughput and availability
while maintaining strong consistency.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jul 25, 2013</span>
        <h2>
          <a class="post-link" href="/2013/07/25/mdcc/">MDCC</a>
        </h2>
	<p>
	  <p>There is a write performance trade off when consistently replicating
across multiple data centers due to the high latency when sending
messages between data centers (often &gt; 100ms).  Existing protocols use
forms of two phase commit which incur 3 blocking round trips between
data centers.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jul 18, 2013</span>
        <h2>
          <a class="post-link" href="/2013/07/18/coralcdn/">CoralCDN</a>
        </h2>
	<p>
	  <p><a href="http://www.coralcdn.org/docs/coral-nsdi04.pdf">CoralCDN</a> is a system
that allows small websites or those with limited resources a method for
remaining available in the face of flash-crowds. The system is
interesting for a number of reasons: it is a live running system that
the public can use, it’s peer to peer, self organizing, and also has a
<a href="http://www.coralcdn.org/docs/coral-nsdi10.pdf">follow-up paper</a> that
analyzes the system with five years of hindsight.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jul 11, 2013</span>
        <h2>
          <a class="post-link" href="/2013/07/11/zookeeper/">Zookeeper</a>
        </h2>
	<p>
	  <p><a href="http://static.usenix.org/event/usenix10/tech/full_papers/Hunt.pdf">Zookeeper</a>
is a practical system with replicated storage used by Yahoo!.  We are
interested in understanding what replication protocol Zookeeper uses,
why they needed a <em>new</em> replication protocol, what applications/services
people build upon it, and what features are required to make such a
replicated storage system practical.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jul 3, 2013</span>
        <h2>
          <a class="post-link" href="/2013/07/03/thialfi/">Thialfi</a>
        </h2>
	<p>
	  <p>Several of the papers we’ve read recently have focused on sophisticated,
generic fault tolerance abstractions based on complex protocols.
<a href="http://www.cs.columbia.edu/~lierranli/coms6998-11Fall2012/papers/thia_sosp2011.pdf">Thialfi</a>
offers a contrast: its approach to fault tolerance is intentionally
simple, while at the same time being resilient to arbitrary (halting)
failure, including entire data centers.  Thialfi’s approach to fault
tolerance permeates the design of its abstraction, unlike Raft and VR,
which provide general-purpose state machine replication.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jun 20, 2013</span>
        <h2>
          <a class="post-link" href="/2013/06/20/vr-revisited/">VR Revisited</a>
        </h2>
	<p>
	  <p><a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf">Viewstamped
Replication</a> is a
mechanism for providing replication through a Primary / Backup scheme.
This paper provides a distilled view of this technique along with
several optimizations that can be applied. In particular, this paper
focuses solely on the Viewstamped Replication protocol, without looking
at any specific implementation or uses.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jun 13, 2013</span>
        <h2>
          <a class="post-link" href="/2013/06/13/cheriton-and-skeen/">Cheriton and Skeen</a>
        </h2>
	<p>
	  <p>Though from 1993, in its time <a href="http://cs3.ist.unomaha.edu/~stanw/papers/93-catocs.pdf">this
paper</a> sparked
some controversy, provoking an impassioned
<a href="http://www.csie.fju.edu.tw/~yeh/research/papers/os-reading-list/birman93response-to-cheriton.pdf">response</a>.
We wanted to understand the debate about the question of providing
ordering guarantees as part of the network.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">Jun 6, 2013</span>
        <h2>
          <a class="post-link" href="/2013/06/06/pacifica/">PacificA</a>
        </h2>
	<p>
	  <p>In the <a href="http://research.microsoft.com/apps/mobile/Publication.aspx?id=66814">PacificA
paper</a>,
the authors describe very clearly how to properly implement a
primary/backup replicated storage layer with strong consistency.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">May 30, 2013</span>
        <h2>
          <a class="post-link" href="/2013/05/30/spanner/">Spanner</a>
        </h2>
	<p>
	  <p><a href="https://www.usenix.org/system/files/conference/osdi12/osdi12-final-16.pdf">Spanner</a>
is a highly distributed, externally consistent database developed by
Google.  It provides replication and transactions over a geographically
distributed set of servers.  Spanner uses time bounds, Paxos, and
two-phase commit to ensure external consistency.</p>


	</p>
      </li>
    
      <li>
        <span class="post-meta">May 23, 2013</span>
        <h2>
          <a class="post-link" href="/2013/05/23/raft/">Raft</a>
        </h2>
	<p>
	  <p><a href="ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf">Raft</a>
is a new consensus algorithm that is optimized for “ease of
implementation”.  Its main purpose is to present a protocol that is more
understandable than Paxos, which, for many practitioners, is difficult
to implement correctly.  Viewstamped Replication is more similar to
Raft, however it is far less popular than Paxos, so it is unfortunately
not focused on in the paper.</p>


	</p>
      </li>
    
  </ul>
</div>


        
      </div>
    </div>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-968607-14', 'auto');
  ga('send', 'pageview');

</script>

  </body>

</html>
